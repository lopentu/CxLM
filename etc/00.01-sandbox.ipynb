{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "207d5614-8283-49fb-b072-1c738c6a193e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchmetrics\n",
    "import torch.optim as optim\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal\n",
    "from torch.distributions import Uniform\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2944eff5-0c8c-4bcb-a38c-2e50ac5f43a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 20\n",
    "mus = torch.ones(D)\n",
    "sigmas = torch.eye(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb745bc4-177f-4e33-af27-bb18eab04f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "mvn = MultivariateNormal(mus, sigmas)\n",
    "unif = Uniform(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c539b6f6-19fb-4b3f-b8ed-fa3ac15eaffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, n_layer=2):        \n",
    "        super(Generator, self).__init__()\n",
    "        self.fc = nn.Sequential(*[\n",
    "            nn.Linear(20, 20), nn.Tanh()]*n_layer)        \n",
    "    def forward(self, X):\n",
    "        return self.fc(X)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, n_layer=2):        \n",
    "        super(Discriminator, self).__init__()\n",
    "        self.fc = nn.Sequential(*[\n",
    "            nn.Linear(20, 20), nn.Tanh()]*n_layer)  \n",
    "        self.cls = nn.Sequential(nn.Linear(20, 1), nn.Sigmoid())\n",
    "        \n",
    "    def forward(self, X):\n",
    "        z = self.fc(X)\n",
    "        out = self.cls(z)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b3494031-d523-4640-9f29-cab97fc18293",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = torchmetrics.Accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3264ebe0-8537-41eb-be8b-6f21df746472",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "G = Generator().cuda()\n",
    "D = Discriminator().cuda()\n",
    "G_loss_mean = torchmetrics.MeanMetric()\n",
    "D_loss_mean = torchmetrics.MeanMetric()\n",
    "reals = mvn.sample((1600,))\n",
    "real_loader = DataLoader(TensorDataset(reals), batch_size=2)\n",
    "optG = optim.AdamW(G.parameters(), lr=0.001)\n",
    "optD = optim.AdamW(D.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bbe17b8f-aeda-40ea-8a68-d80b88d7fb1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_D: -0.0039813625626266, loss_G: -0.48899349570274353\n",
      "loss_D: -0.005479327403008938, loss_G: -0.49022579193115234\n",
      "loss_D: -0.014151657931506634, loss_G: -0.4780244827270508\n",
      "loss_D: -0.01222685631364584, loss_G: -0.48399192094802856\n",
      "loss_D: -0.011000297032296658, loss_G: -0.478678435087204\n",
      "loss_D: -0.009856012649834156, loss_G: -0.48085400462150574\n",
      "loss_D: -0.009009427390992641, loss_G: -0.4768573045730591\n",
      "loss_D: -0.008427336812019348, loss_G: -0.47773244976997375\n",
      "loss_D: -0.008702069520950317, loss_G: -0.47769883275032043\n",
      "loss_D: -0.00877364818006754, loss_G: -0.47497087717056274\n"
     ]
    }
   ],
   "source": [
    "train_gen = True\n",
    "for epoch_i in range(10):\n",
    "    for (real_batch,) in real_loader:\n",
    "        real_batch = real_batch.cuda()\n",
    "        optD.zero_grad()\n",
    "        z = unif.sample((32, 20)).cuda()\n",
    "        fakes = G(z)\n",
    "        loss_D = -torch.mean(D(real_batch)) + torch.mean(D(fakes.detach()))\n",
    "        loss_D.backward()\n",
    "        optD.step()\n",
    "        D_loss_mean.update(loss_D.item())\n",
    "        for p in D.parameters():\n",
    "            p.data.clamp_(-0.1, 0.1)\n",
    "\n",
    "        ## train generator\n",
    "        if train_gen:    \n",
    "            optG.zero_grad()\n",
    "            loss_G = -torch.mean(D(fakes))\n",
    "            loss_G.backward()\n",
    "            optG.step()\n",
    "            G_loss_mean.update(loss_G.item())     \n",
    "    print(f\"loss_D: {D_loss_mean.compute().item()}, loss_G: {G_loss_mean.compute().item()}\")    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20331c21-2e9e-43ee-b2af-adbe79ce654f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

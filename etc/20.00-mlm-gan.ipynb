{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "947f7331-799e-457e-9b05-f707abd298e9",
   "metadata": {},
   "source": [
    "## GAN for MLM\n",
    "* Inputs:\n",
    "  * raw data: `../data/raw_cx_data.json` (10.01)\n",
    "  * CV splits: `../data/cv_splits_10.json` (10.01)\n",
    "* Outputs:\n",
    "  * (none)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a002c61d-99e2-4e20-a1fd-8d739a3afd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46b8acef-ef12-40d0-9d27-fde1bd8b7f00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from hashlib import sha256\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from transformers import BertTokenizerFast, BertForMaskedLM, BertModel\n",
    "from import_conart import conart\n",
    "from conart.mlm_masks import batched_text_gan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b571992-7a21-4000-80e1-bab0f9d8babb",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") \\\n",
    "         if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9a62670-63f0-45f2-98b1-f8aa45b47866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11642"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = \"../data/raw_cx_data.json\"\n",
    "with open(data_path, \"r\", encoding=\"UTF-8\") as fin:\n",
    "    data = json.load(fin)\n",
    "## Check data is the same\n",
    "h = sha256()\n",
    "h.update(pickle.dumps(data))\n",
    "data_hash = h.digest().hex()[:6]\n",
    "assert data_hash == \"4063b4\"\n",
    "len(data) # should be 11642"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7556dcc-1a31-40c8-b142-9a41f7e4ab47",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read cv splits\n",
    "with open(\"../data/cv_splits_10.json\", \"r\") as fin:\n",
    "    cv_splits = json.load(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46be44f6-5e00-4f5c-ac66-aec6f4441879",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-chinese')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce38a19-96c3-44c8-9985-a513758804be",
   "metadata": {},
   "source": [
    "## Checking input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d978cb6d-17eb-45b4-95a9-ece138f1f9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idxs, test_idxs = cv_splits[0].values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab1179ed-8332-46d9-99af-e5ca98da2f6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'board': 'BabyMother',\n",
       " 'text': ['再', '擠', '也', '擠', '不', '出來', '了'],\n",
       " 'cnstr': ['O', 'BX', 'IX', 'IX', 'IX', 'IX', 'O'],\n",
       " 'slot': ['O', 'BV', 'BC', 'BV', 'BC', 'BV', 'O'],\n",
       " 'cnstr_form': ['v', '也', 'v', '不', 'X'],\n",
       " 'cnstr_example': ['擠', '也', '擠', '不', '出來']}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx = data[1211]\n",
    "xx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a826fa-19ed-488b-b4dd-bae771ec8094",
   "metadata": {},
   "source": [
    "## Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c39107d4-75f8-46fe-9654-104ba544322d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idxs_ds = TensorDataset(torch.tensor(train_idxs))\n",
    "test_idxs_ds = TensorDataset(torch.tensor(test_idxs))\n",
    "cx_lenc = LabelEncoder()\n",
    "cx_lenc.classes_ = [\"[PAD]\", \"BX\", \"IX\", \"O\"]\n",
    "slot_lenc = LabelEncoder()\n",
    "slot_lenc.classes_ = [\"[PAD]\", \"BC\", \"IC\", \"BV\", \"IV\", \"O\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6a45f91-251c-4579-9f55-8d45a3efe523",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gan_collate_fn(X, data, cx_lenc, slot_lenc, device=\"cpu\"):  \n",
    "    idxs = [x[0].item() for x in X]\n",
    "    batch = batched_text_gan(data, idxs)\n",
    "    \n",
    "    tokens = tokenizer(batch[\"text\"], return_tensors=\"pt\", \n",
    "                          is_split_into_words=True, padding=True, truncation=True)    \n",
    "    \n",
    "    cx_tags = [torch.tensor(cx_lenc.transform([\"[PAD]\"] + x + [\"[PAD]\"]))\n",
    "               for x in batch[\"cx_tags\"]]\n",
    "    cx_tags = pad_sequence(cx_tags, batch_first=True, padding_value=0)\n",
    "    cx_tags = cx_tags[:, :tokens.input_ids.size(1)]\n",
    "    \n",
    "    slot_tags = [torch.tensor(slot_lenc.transform([\"[PAD]\"] + x + [\"[PAD]\"])) \n",
    "                 for x in batch[\"slot_tags\"]]        \n",
    "    slot_tags = pad_sequence(slot_tags, batch_first=True, padding_value=0)\n",
    "    slot_tags = slot_tags[:, :tokens.input_ids.size(1)]\n",
    "    batch[\"cx_tags\"] = cx_tags.to(device)\n",
    "    batch[\"slot_tags\"] = slot_tags.to(device)\n",
    "    batch[\"text\"] = tokens.to(device)\n",
    "    \n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c167c40d-6d11-41a0-9c46-af5f3f3e28de",
   "metadata": {},
   "outputs": [],
   "source": [
    "bb = gan_collate_fn([test_idxs_ds[202], test_idxs_ds[203]], data, cx_lenc, slot_lenc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "407f60b1-db74-4b14-940b-8821d1c1a4fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': {'input_ids': tensor([[ 101,  738, 3221, 4684, 2970, 6842,  671, 6842, 3862, 7295, 1921, 4958,\n",
       "           749,  102,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0],\n",
       "         [ 101,  872,  738, 2523, 4735, 3146, 1921, 3819, 5582, 5632, 2346,  872,\n",
       "          4511, 1351, 1168, 2419, 3221, 1914, 2483, 3255, 6865, 6134, 6888, 6963,\n",
       "          6134, 6888,  679, 1962,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1]])},\n",
       " 'cx_tags': tensor([[0, 3, 3, 3, 3, 1, 2, 2, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0],\n",
       "         [0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 2, 2,\n",
       "          2, 2, 2, 2, 0]]),\n",
       " 'slot_tags': tensor([[0, 5, 5, 5, 5, 3, 1, 3, 5, 5, 5, 5, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0],\n",
       "         [0, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 3, 4, 1,\n",
       "          3, 4, 1, 3, 0]])}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc6390e7-1e7e-4e85-8f7c-eee3f657cac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS],0', '也,5', '是,5', '直,5', '接,5', '退,3', '一,1', '退,3', '海,5', '闊,5', '天,5', '空,5', '了,5', '[SEP],0', '[PAD],0', '[PAD],0', '[PAD],0', '[PAD],0', '[PAD],0', '[PAD],0', '[PAD],0', '[PAD],0', '[PAD],0', '[PAD],0', '[PAD],0', '[PAD],0', '[PAD],0', '[PAD],0', '[PAD],0']\n",
      "['[CLS],0', '也,3', '是,3', '直,3', '接,3', '退,1', '一,2', '退,2', '海,3', '闊,3', '天,3', '空,3', '了,3', '[SEP],0', '[PAD],0', '[PAD],0', '[PAD],0', '[PAD],0', '[PAD],0', '[PAD],0', '[PAD],0', '[PAD],0', '[PAD],0', '[PAD],0', '[PAD],0', '[PAD],0', '[PAD],0', '[PAD],0', '[PAD],0']\n"
     ]
    }
   ],
   "source": [
    "## visual check\n",
    "print([f\"{a},{b.item()}\" for a,b in zip(tokenizer.convert_ids_to_tokens(bb[\"text\"].input_ids[0]), bb[\"slot_tags\"][0])])\n",
    "print([f\"{a},{b.item()}\" for a,b in zip(tokenizer.convert_ids_to_tokens(bb[\"text\"].input_ids[0]), bb[\"cx_tags\"][0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "31ec668b-2eda-4297-a768-a0ae856d5fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "collate_fn = lambda x: gan_collate_fn(x, data, cx_lenc, slot_lenc, device)\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(train_idxs_ds, batch_size=batch_size, shuffle=True, \n",
    "                         collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_idxs_ds, batch_size=batch_size, shuffle=True, \n",
    "                         collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "20ecccfd-35fc-4a47-a231-7b59b8aa3c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch size:  16\n",
      "Training dataset: 10477\n",
      "Testing dataset: 1165\n"
     ]
    }
   ],
   "source": [
    "print(\"batch size: \", batch_size)\n",
    "print(\"Training dataset:\", len(train_idxs_ds))\n",
    "print(\"Testing dataset:\", len(test_idxs_ds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1f7ac3-3fbd-4462-8ee6-91dca4cd81fc",
   "metadata": {},
   "source": [
    "## Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fba799d8-1901-4b97-82bd-036d09e10c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertPreTrainedModel, BertModel, BertForMaskedLM\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "47553e9c-1166-4afc-b6ad-e367326add95",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConartModelApricot(BertForMaskedLM):\n",
    "    def __init__(self, config):\n",
    "        super(ConartModelApricot, self).__init__(config)\n",
    "        # inherit self.bert, self.cls (lm head) from super()\n",
    "        self.lm_cls = self.cls\n",
    "        self.tok_cls = nn.Linear(config.hidden_size, config.num_labels)\n",
    "        self.init_weights()\n",
    "    \n",
    "    def G_params(self):\n",
    "        return [self.bert.parameters(), self.cls.parameters()]\n",
    "    \n",
    "    def D_params(self):\n",
    "        return [self.bert.parameters(), self.tok_cls.parameters()]\n",
    "    \n",
    "    def forward_G(self, X):\n",
    "        out = self.forward(X)\n",
    "        return self.lm_cls(out.last_hidden_state)\n",
    "    \n",
    "    def forward_D(self, X):\n",
    "        out = self.forward(X)\n",
    "        return self.tok_cls(out.last_hidden_state)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        tokens = X[\"text\"]\n",
    "        cx_tags = X[\"cx_tags\"]\n",
    "        slot_tags = X[\"slot_tags\"]\n",
    "        bert_out = self.bert(**tokens, return_dict=True)\n",
    "        return bert_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "827d7764-c216-4924-b193-970d2af3538f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ConartModelApricot were not initialized from the model checkpoint at ckiplab/bert-base-chinese and are newly initialized: ['lm_cls.predictions.transform.LayerNorm.weight', 'lm_cls.predictions.transform.dense.weight', 'lm_cls.predictions.bias', 'lm_cls.predictions.decoder.weight', 'tok_cls.weight', 'tok_cls.bias', 'lm_cls.predictions.transform.dense.bias', 'lm_cls.predictions.transform.LayerNorm.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# model = BertForMaskedLM.from_pretrained('bert-base-chinese')\n",
    "model = ConartModelApricot.from_pretrained(\"ckiplab/bert-base-chinese\", num_labels=len(cx_lenc.classes_))\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "86d6e4ce-fa86-4c73-b575-8cbe7bc721db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 73, 768])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bb = next(iter(test_loader))\n",
    "model.forward(bb).last_hidden_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6e4985a8-22a5-464a-ad1f-54cae7d50710",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_probs = model.forward_G(bb)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a53be522-4874-4249-9086-0e3bbbb5ff26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([73, 21128])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2413580c-8542-45a0-8d8e-e1252688a76d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[PAD]', 'BC', 'IC', 'BV', 'IV', 'O']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slot_lenc.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f442fc23-5e48-4269-a517-e9be4ecc2a9b",
   "metadata": {},
   "source": [
    "## Prepare fake/real mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "de2dc23f-d6cf-499b-acf3-7bbfb1ec8caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140646856712704\n",
      "140646856712704\n"
     ]
    }
   ],
   "source": [
    "BV_id = slot_lenc.transform([\"BV\"])[0]\n",
    "IV_id = slot_lenc.transform([\"IV\"])[0]\n",
    "slot_mask = bb[\"slot_tags\"] != 0\n",
    "adv_labels = (bb[\"slot_tags\"] == BV_id).clone()\n",
    "print(adv_labels.data_ptr())\n",
    "adv_labels = torch.logical_or(adv_labels, bb[\"slot_tags\"] == IV_id, out=adv_labels)\n",
    "print(adv_labels.data_ptr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6a4fcc4f-e52b-438d-8a1a-da75fb93dc69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-100,    1,    1,  ..., -100, -100, -100],\n",
       "        [-100,    1,    0,  ..., -100, -100, -100],\n",
       "        [-100,    1,    1,  ..., -100, -100, -100],\n",
       "        ...,\n",
       "        [-100,    1,    0,  ..., -100, -100, -100],\n",
       "        [-100,    1,    1,  ..., -100, -100, -100],\n",
       "        [-100,    1,    1,  ..., -100, -100, -100]], device='cuda:0')"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate GAN real/fake labels\n",
    "gen_labels = torch.full_like(bb[\"slot_tags\"], -100)\n",
    "gen_labels.masked_fill_(adv_labels, 1)\n",
    "dcr_real_mask = torch.logical_and(slot_mask, adv_labels.logical_not())\n",
    "dcr_fake_mask = torch.logical_and(slot_mask, adv_labels)\n",
    "dcr_labels = torch.full_like(bb[\"slot_tags\"], -100)\n",
    "dcr_labels.masked_fill_(dcr_real_mask, 1)\n",
    "dcr_labels.masked_fill_(dcr_fake_mask, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3ce21a-ead2-4f60-82a3-6eaa1a7dc916",
   "metadata": {},
   "source": [
    "## Eye-balling fake/real labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e3fcc4bb-1694-4561-87d8-bea26df61c17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[PAD] [PAD] [PAD] [PAD] 看 [PAD] [PAD] 看 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## should only show variable sites\n",
    "tokenizer.decode(bb[\"text\"].input_ids.masked_fill(gen_labels!=1, 0)[0, :40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "03121e98-ae1b-4cab-a864-ff60e105217e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[PAD] 內 文 連 [PAD] 都 沒 [PAD] 的 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## should only show non-fake sites (discriminator should say 'real')\n",
    "tokenizer.decode(bb[\"text\"].input_ids.masked_fill(dcr_labels!=1, 0)[0, :40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "cc2fcc0d-0ee4-4c41-8f0f-10662c6ac00e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[PAD] [PAD] [PAD] [PAD] 看 [PAD] [PAD] 看 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## should only show fake sites (discriminator should say 'fake')\n",
    "tokenizer.decode(bb[\"text\"].input_ids.masked_fill(dcr_labels!=0, 0)[0, :40])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14577bbb-f6b8-4aad-9951-56a044866442",
   "metadata": {},
   "source": [
    "## Generate Adversarial sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "535b9689-b5ea-4c7e-a41f-37b3c6f853ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_ids = bb[\"text\"].input_ids.clone()\n",
    "lm_probs = model.forward_G(bb).softmax(dim=2)\n",
    "adv_ids[gen_labels==1] = torch.multinomial(lm_probs[gen_labels==1], 1).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "db7f538c-a2d3-4275-b041-d72123661c9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS] 內 文 連 看 都 沒 看 的 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]',\n",
       " '[CLS] 1 喝 都 喝 了 也 沒 辦 法 催 吐 吧 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]',\n",
       " '[CLS] 可 以 一 推 再 推 呀 愈 多 人 推 就 代 表 那 首 愈 讚 [UNK] [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]',\n",
       " '[CLS] 連 拆 都 沒 拆 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]',\n",
       " '[CLS] 後 來 改 吃 鹽 埕 區 的 水 源 羊 肉 了 要 試 一 試 元 豐 羊 肉 嗎 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]',\n",
       " '[CLS] 人 一 多 就 整 個 炸 掉 了 吧 過 年 人 車 都 回 來 了 [UNK] 對 阿 附 近 多 出 一 堆 車 亂',\n",
       " '[CLS] 叫 也 叫 不 回 說 剛 剛 那 個 動 作 讓 她 覺 得 在 別 人 面 前 丟 臉 看 電 影 [SEP] [PAD] [PAD]',\n",
       " '[CLS] 多 買 一 片 是 一 片 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]',\n",
       " '[CLS] 你 要 嘛 聽 一 聽 就 好 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]',\n",
       " '[CLS] 如 果 一 天 比 一 天 好 轉 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]',\n",
       " '[CLS] 現 在 找 也 找 不 到 了 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]',\n",
       " '[CLS] 不 趕 快 把 帳 出 一 出 的 話 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]',\n",
       " '[CLS] 3 _ 4 個 所 以 一 個 小 孩 才 會 是 月 薪 1 _ 6 至 2 _ 2 萬 而 已 幼 稚 園 回',\n",
       " '[CLS] 連 聽 都 沒 聽 過 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]',\n",
       " '[CLS] 沒 什 麼 穩 不 穩 的 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]',\n",
       " '[CLS] 他 們 只 會 一 賭 再 賭 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]']"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(adv_ids[:, :30])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d360e047-8103-4a0f-a8dd-953dd28052e5",
   "metadata": {},
   "source": [
    "## Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a56298-3cbc-4a7a-a4b3-2230908cd48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.forward_D(bb).argmax(2)[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

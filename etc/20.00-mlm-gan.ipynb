{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "947f7331-799e-457e-9b05-f707abd298e9",
   "metadata": {},
   "source": [
    "## GAN for MLM\n",
    "* Inputs:\n",
    "  * raw data: `../data/raw_cx_data.json` (10.01)\n",
    "  * CV splits: `../data/cv_splits_10.json` (10.01)\n",
    "* Outputs:\n",
    "  * (none)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a002c61d-99e2-4e20-a1fd-8d739a3afd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46b8acef-ef12-40d0-9d27-fde1bd8b7f00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from hashlib import sha256\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from transformers import BertTokenizerFast, BertForMaskedLM, BertModel\n",
    "from import_conart import conart\n",
    "from conart.mlm_masks import batched_text_gan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b571992-7a21-4000-80e1-bab0f9d8babb",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") \\\n",
    "         if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9a62670-63f0-45f2-98b1-f8aa45b47866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11642"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = \"../data/raw_cx_data.json\"\n",
    "with open(data_path, \"r\", encoding=\"UTF-8\") as fin:\n",
    "    data = json.load(fin)\n",
    "## Check data is the same\n",
    "h = sha256()\n",
    "h.update(pickle.dumps(data))\n",
    "data_hash = h.digest().hex()[:6]\n",
    "assert data_hash == \"4063b4\"\n",
    "len(data) # should be 11642"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7556dcc-1a31-40c8-b142-9a41f7e4ab47",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read cv splits\n",
    "with open(\"../data/cv_splits_10.json\", \"r\") as fin:\n",
    "    cv_splits = json.load(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46be44f6-5e00-4f5c-ac66-aec6f4441879",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-chinese')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce38a19-96c3-44c8-9985-a513758804be",
   "metadata": {},
   "source": [
    "## Checking input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d978cb6d-17eb-45b4-95a9-ece138f1f9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idxs, test_idxs = cv_splits[0].values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab1179ed-8332-46d9-99af-e5ca98da2f6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'board': 'BabyMother',\n",
       " 'text': ['再', '擠', '也', '擠', '不', '出來', '了'],\n",
       " 'cnstr': ['O', 'BX', 'IX', 'IX', 'IX', 'IX', 'O'],\n",
       " 'slot': ['O', 'BV', 'BC', 'BV', 'BC', 'BV', 'O'],\n",
       " 'cnstr_form': ['v', '也', 'v', '不', 'X'],\n",
       " 'cnstr_example': ['擠', '也', '擠', '不', '出來']}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx = data[1211]\n",
    "xx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a826fa-19ed-488b-b4dd-bae771ec8094",
   "metadata": {},
   "source": [
    "## Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c39107d4-75f8-46fe-9654-104ba544322d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idxs_ds = TensorDataset(torch.tensor(train_idxs))\n",
    "test_idxs_ds = TensorDataset(torch.tensor(test_idxs))\n",
    "cx_lenc = LabelEncoder()\n",
    "cx_lenc.classes_ = [\"[PAD]\", \"BX\", \"IX\", \"O\"]\n",
    "slot_lenc = LabelEncoder()\n",
    "slot_lenc.classes_ = [\"[PAD]\", \"BC\", \"IC\", \"BV\", \"IV\", \"O\"]\n",
    "adv_lenc = LabelEncoder()\n",
    "adv_lenc.classes_ = [\"fake\", \"real\"]\n",
    "BV_id = slot_lenc.transform([\"BV\"])[0]\n",
    "IV_id = slot_lenc.transform([\"IV\"])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f4503313-a5de-4e5d-9259-984d2d96eabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_gendcr_labels(batch):\n",
    "    # create adv_labels, where cell value is a 1 if it is a variable (BV/IV)\n",
    "    # otherwise, it's a 0.\n",
    "    slot_tags = batch[\"slot_tags\"]\n",
    "    slot_mask = slot_tags != 0\n",
    "    adv_labels = (slot_tags == BV_id).clone()    \n",
    "    adv_labels = torch.logical_or(adv_labels, slot_tags==IV_id, out=adv_labels)\n",
    "    \n",
    "    # generate GAN real/fake labels\n",
    "    gen_labels = torch.full_like(slot_tags, -100)\n",
    "    gen_labels.masked_fill_(adv_labels, 1)\n",
    "    dcr_real_mask = torch.logical_and(slot_mask, adv_labels.logical_not())\n",
    "    dcr_fake_mask = torch.logical_and(slot_mask, adv_labels)\n",
    "    dcr_labels = torch.full_like(slot_tags, -100)\n",
    "    dcr_labels.masked_fill_(dcr_real_mask, 1)\n",
    "    dcr_labels.masked_fill_(dcr_fake_mask, 0)\n",
    "    return {\"gen_labels\": gen_labels, \"dcr_labels\": dcr_labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8be1f4b0-5798-4fca-8879-e1e25ccfbd06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[101, 738, 3221, 4684, 2970, 103, 671, 103, 3862, 7295, 1921, 4958, 749, 102], [101, 872, 738, 2523, 4735, 3146, 1921, 3819, 5582, 5632, 2346, 872, 4511, 1351, 1168, 2419, 3221, 1914, 2483, 3255, 6865, 103, 103, 6963, 103, 103, 679, 103, 102]]}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(bb[\"masked\"], is_split_into_words=True, return_token_type_ids=False, return_attention_mask=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b6a45f91-251c-4579-9f55-8d45a3efe523",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gan_collate_fn(X, data, cx_lenc, slot_lenc, device=\"cpu\"):  \n",
    "    idxs = [x[0].item() for x in X]\n",
    "    batch = batched_text_gan(data, idxs)\n",
    "    \n",
    "    real_tokens = tokenizer(batch[\"text\"], return_tensors=\"pt\", \n",
    "                          is_split_into_words=True, padding=True, truncation=True,\n",
    "                          return_token_type_ids=False, return_attention_mask=False)    \n",
    "    masked_tokens = tokenizer(batch[\"masked\"], return_tensors=\"pt\", \n",
    "                          is_split_into_words=True, padding=True, truncation=True)    \n",
    "    \n",
    "    cx_tags = [torch.tensor(cx_lenc.transform([\"[PAD]\"] + x + [\"[PAD]\"]))\n",
    "               for x in batch[\"cx_tags\"]]\n",
    "    cx_tags = pad_sequence(cx_tags, batch_first=True, padding_value=0)\n",
    "    cx_tags = cx_tags[:, :real_tokens.input_ids.size(1)]\n",
    "    \n",
    "    slot_tags = [torch.tensor(slot_lenc.transform([\"[PAD]\"] + x + [\"[PAD]\"])) \n",
    "                 for x in batch[\"slot_tags\"]]        \n",
    "    slot_tags = pad_sequence(slot_tags, batch_first=True, padding_value=0)\n",
    "    slot_tags = slot_tags[:, :real_tokens.input_ids.size(1)]\n",
    "    batch[\"cx_tags\"] = cx_tags.to(device)\n",
    "    batch[\"slot_tags\"] = slot_tags.to(device)\n",
    "    batch[\"real_text\"] = real_tokens.to(device)\n",
    "    batch[\"masked_text\"] = masked_tokens.to(device)\n",
    "    batch.update(make_gendcr_labels(batch))\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c167c40d-6d11-41a0-9c46-af5f3f3e28de",
   "metadata": {},
   "outputs": [],
   "source": [
    "bb = gan_collate_fn([test_idxs_ds[202], test_idxs_ds[203]], data, cx_lenc, slot_lenc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "407f60b1-db74-4b14-940b-8821d1c1a4fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['text',\n",
       " 'masked',\n",
       " 'cx_tags',\n",
       " 'slot_tags',\n",
       " 'real_text',\n",
       " 'masked_text',\n",
       " 'gen_labels',\n",
       " 'dcr_labels']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(bb.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cc6390e7-1e7e-4e85-8f7c-eee3f657cac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS],0', '也,5', '是,5', '直,5', '接,5', '退,3', '一,1', '退,3', '海,5', '闊,5', '天,5', '空,5', '了,5', '[SEP],0', '[PAD],0', '[PAD],0', '[PAD],0', '[PAD],0', '[PAD],0', '[PAD],0', '[PAD],0', '[PAD],0', '[PAD],0', '[PAD],0', '[PAD],0', '[PAD],0', '[PAD],0', '[PAD],0', '[PAD],0']\n",
      "['[CLS],0', '也,3', '是,3', '直,3', '接,3', '退,1', '一,2', '退,2', '海,3', '闊,3', '天,3', '空,3', '了,3', '[SEP],0', '[PAD],0', '[PAD],0', '[PAD],0', '[PAD],0', '[PAD],0', '[PAD],0', '[PAD],0', '[PAD],0', '[PAD],0', '[PAD],0', '[PAD],0', '[PAD],0', '[PAD],0', '[PAD],0', '[PAD],0']\n"
     ]
    }
   ],
   "source": [
    "## visual check\n",
    "print([f\"{a},{b.item()}\" for a,b in zip(tokenizer.convert_ids_to_tokens(bb[\"real_text\"].input_ids[0]), bb[\"slot_tags\"][0])])\n",
    "print([f\"{a},{b.item()}\" for a,b in zip(tokenizer.convert_ids_to_tokens(bb[\"real_text\"].input_ids[0]), bb[\"cx_tags\"][0])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3ce21a-ead2-4f60-82a3-6eaa1a7dc916",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Eye-balling fake/real labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e3fcc4bb-1694-4561-87d8-bea26df61c17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[PAD] [PAD] [PAD] [PAD] [PAD] 退 [PAD] 退 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## should only show variable sites\n",
    "tokenizer.decode(bb[\"real_text\"].input_ids.masked_fill(bb[\"gen_labels\"]!=1, 0)[0, :40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "03121e98-ae1b-4cab-a864-ff60e105217e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[PAD] 也 是 直 接 [PAD] 一 [PAD] 海 闊 天 空 了 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## should only show non-fake sites (discriminator should say 'real')\n",
    "tokenizer.decode(bb[\"real_text\"].input_ids.masked_fill(bb[\"dcr_labels\"]!=1, 0)[0, :40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cc2fcc0d-0ee4-4c41-8f0f-10662c6ac00e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[PAD] [PAD] [PAD] [PAD] [PAD] 退 [PAD] 退 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## should only show fake sites (discriminator should say 'fake')\n",
    "tokenizer.decode(bb[\"real_text\"].input_ids.masked_fill(bb[\"dcr_labels\"]!=0, 0)[0, :40])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1f7ac3-3fbd-4462-8ee6-91dca4cd81fc",
   "metadata": {},
   "source": [
    "## Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fba799d8-1901-4b97-82bd-036d09e10c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertPreTrainedModel, BertModel, BertForMaskedLM\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "47553e9c-1166-4afc-b6ad-e367326add95",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConartModelApricot(BertForMaskedLM):\n",
    "    def __init__(self, config):\n",
    "        super(ConartModelApricot, self).__init__(config)\n",
    "        # inherit self.bert, self.cls (lm head) from super()\n",
    "        self.lm_cls = self.cls\n",
    "        self.tok_cls = nn.Linear(config.hidden_size, config.num_labels)\n",
    "        self.init_weights()\n",
    "    \n",
    "    def G_params(self):\n",
    "        return [self.bert.parameters(), self.cls.parameters()]\n",
    "    \n",
    "    def D_params(self):\n",
    "        return [self.bert.parameters(), self.tok_cls.parameters()]\n",
    "    \n",
    "    def forward_G(self, X):\n",
    "        out = self.forward(X)\n",
    "        return self.lm_cls(out.last_hidden_state)\n",
    "    \n",
    "    def forward_D(self, X):\n",
    "        out = self.forward(X)\n",
    "        return self.tok_cls(out.last_hidden_state)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        tokens = X[\"masked_text\"]\n",
    "        cx_tags = X[\"cx_tags\"]\n",
    "        slot_tags = X[\"slot_tags\"]\n",
    "        bert_out = self.bert(**tokens, return_dict=True)\n",
    "        return bert_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea8c3ba-54ab-48e2-a0ab-9374a21c1814",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "31ec668b-2eda-4297-a768-a0ae856d5fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "collate_fn = lambda x: gan_collate_fn(x, data, cx_lenc, slot_lenc, device)\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(train_idxs_ds, batch_size=batch_size, shuffle=True, \n",
    "                         collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_idxs_ds, batch_size=batch_size, shuffle=True, \n",
    "                         collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "20ecccfd-35fc-4a47-a231-7b59b8aa3c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch size:  16\n",
      "Training dataset: 10477\n",
      "Testing dataset: 1165\n"
     ]
    }
   ],
   "source": [
    "print(\"batch size: \", batch_size)\n",
    "print(\"Training dataset:\", len(train_idxs_ds))\n",
    "print(\"Testing dataset:\", len(test_idxs_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "827d7764-c216-4924-b193-970d2af3538f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ConartModelApricot were not initialized from the model checkpoint at ckiplab/bert-base-chinese and are newly initialized: ['lm_cls.predictions.transform.dense.weight', 'tok_cls.weight', 'tok_cls.bias', 'lm_cls.predictions.transform.dense.bias', 'lm_cls.predictions.decoder.weight', 'lm_cls.predictions.transform.LayerNorm.weight', 'lm_cls.predictions.transform.LayerNorm.bias', 'lm_cls.predictions.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# model = BertForMaskedLM.from_pretrained('bert-base-chinese')\n",
    "model = ConartModelApricot.from_pretrained(\"ckiplab/bert-base-chinese\", num_labels=len(cx_lenc.classes_))\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "86d6e4ce-fa86-4c73-b575-8cbe7bc721db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 46, 768])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bb = next(iter(test_loader))\n",
    "model.forward(bb).last_hidden_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6e4985a8-22a5-464a-ad1f-54cae7d50710",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_probs = model.forward_G(bb)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a53be522-4874-4249-9086-0e3bbbb5ff26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([46, 21128])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_probs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14577bbb-f6b8-4aad-9951-56a044866442",
   "metadata": {},
   "source": [
    "## Generate Adversarial sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "db7f538c-a2d3-4275-b041-d72123661c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_adv(adv_data, maxlen=20):\n",
    "    adv_ids = adv_data[\"adv_ids\"]\n",
    "    real_ids = adv_data[\"real_ids\"]\n",
    "    dcr_masks = adv_data[\"dcr_labels\"]\n",
    "    for i in range(adv_ids.size(0)):\n",
    "        adv_seq = adv_ids[i].tolist()[:maxlen]\n",
    "        real_seq = real_ids[i].tolist()[:maxlen]\n",
    "        dcr_seq = dcr_masks[i].tolist()[:maxlen]\n",
    "        tr = tokenizer.decode\n",
    "        for a, r, d in zip(adv_seq, real_seq, dcr_seq):\n",
    "            ach = tr(a); rch = tr(r)\n",
    "            ch = rch if d else \\\n",
    "                 f\"\\x1b[31m{ach}(\\x1b[4m{rch}\\x1b[0;31m)\\x1b[0m\"\n",
    "            print(ch, end='')\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "535b9689-b5ea-4c7e-a41f-37b3c6f853ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]不是有醫生說成人都不見得能整天了何況是\n",
      "[CLS]我怎麼\u001b[31m想(\u001b[4m找\u001b[0;31m)\u001b[0m都\u001b[31m辦(\u001b[4m找\u001b[0;31m)\u001b[0m不到[UNK][UNK]追殺列車攤大的[UNK]h\n",
      "[CLS]這種店\u001b[31m鎮(\u001b[4m收\u001b[0;31m)\u001b[0m一\u001b[31m,(\u001b[4m收\u001b[0;31m)\u001b[0m反正也沒人想去吃走一下進度\n",
      "[CLS]說\u001b[31m完(\u001b[4m黑\u001b[0;31m)\u001b[0m就\u001b[31m乾(\u001b[4m黑\u001b[0;31m)\u001b[0m吧[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
      "[CLS]沒作業就讓我們\u001b[31m幹(\u001b[4m動\u001b[0;31m)\u001b[0m一\u001b[31m下(\u001b[4m動\u001b[0;31m)\u001b[0m嘛[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
      "[CLS]書名說媽媽有病控制狂有毒的書都去看一\u001b[31m覽(\u001b[4m看\u001b[0;31m)\u001b[0m\n",
      "[CLS]能\u001b[31m是(\u001b[4m醒\u001b[0;31m)\u001b[0m一\u001b[31m定(\u001b[4m個\u001b[0;31m)\u001b[0m是一\u001b[31m樣(\u001b[4m個\u001b[0;31m)\u001b[0m吧我認為[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
      "[CLS]希望可以把樂高雄這個名字也\u001b[31m來(\u001b[4m改\u001b[0;31m)\u001b[0m一\u001b[31m起(\u001b[4m改\u001b[0;31m)\u001b[0m[SEP][PAD][PAD]\n",
      "[CLS]敢\u001b[31m不(\u001b[4m玩\u001b[0;31m)\u001b[0m敢\u001b[31m。(\u001b[4m冒\u001b[0;31m)\u001b[0m\u001b[31m##llow(\u001b[4m險\u001b[0;31m)\u001b[0m[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
      "[CLS]但想先\u001b[31m來(\u001b[4m問\u001b[0;31m)\u001b[0m\u001b[31m聽(\u001b[4m問\u001b[0;31m)\u001b[0m看大家的意見[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
      "[CLS]頭也是頭髮在肩上\u001b[31m,(\u001b[4m甩\u001b[0;31m)\u001b[0m來\u001b[31m滾(\u001b[4m甩\u001b[0;31m)\u001b[0m去[SEP][PAD][PAD][PAD][PAD][PAD][PAD]\n",
      "[CLS]每天就是在家大眼瞪小眼\u001b[31m,(\u001b[4m搞\u001b[0;31m)\u001b[0m一\u001b[31m至(\u001b[4m搞\u001b[0;31m)\u001b[0m現在禮拜天\n",
      "[CLS]\u001b[31m久(\u001b[4m算\u001b[0;31m)\u001b[0m一\u001b[31m些(\u001b[4m算\u001b[0;31m)\u001b[0m時間也該停了怎變這樣哩但在之前要\n",
      "[CLS]適度顧慮是應該但妳媽是過度不大氣而妳弱\n",
      "[CLS]連\u001b[31m水(\u001b[4m喝\u001b[0;31m)\u001b[0m都沒\u001b[31m有(\u001b[4m喝\u001b[0;31m)\u001b[0m囧媽媽躲起來讓別人瓶餵[SEP][PAD][PAD]\n",
      "[CLS]我想跟妳\u001b[31m摸(\u001b[4m談\u001b[0;31m)\u001b[0m一\u001b[31m作(\u001b[4m談\u001b[0;31m)\u001b[0m[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n"
     ]
    }
   ],
   "source": [
    "def generate_adversarials(batch, lm_prob):\n",
    "    adv_ids = batch[\"masked_text\"].input_ids.clone()    \n",
    "    gen_labels = batch[\"gen_labels\"]\n",
    "    adv_ids[gen_labels==1] = torch.multinomial(lm_probs[gen_labels==1], 1).squeeze()\n",
    "    real_ids = bb[\"real_text\"].input_ids\n",
    "    dcr_labels = adv_ids == real_ids\n",
    "    return {\"adv_ids\": adv_ids, \"real_ids\": real_ids, \n",
    "            \"dcr_labels\": dcr_labels}\n",
    "lm_probs = model.forward_G(bb).softmax(dim=2)\n",
    "adv_out = generate_adversarials(bb, lm_probs)\n",
    "visualize_adv(adv_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d360e047-8103-4a0f-a8dd-953dd28052e5",
   "metadata": {},
   "source": [
    "## Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a56298-3cbc-4a7a-a4b3-2230908cd48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.forward_D(bb).argmax(2)[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

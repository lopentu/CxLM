{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "947f7331-799e-457e-9b05-f707abd298e9",
   "metadata": {},
   "source": [
    "## MLM-tuned Accuracies\n",
    "* Inputs:\n",
    "  * raw data: `../data/raw_cx_data.json` (10.01)\n",
    "  * CV splits: `../data/cv_splits_10.json` (10.01)\n",
    "  * MLM-tuned: `../data/models/apricot_mlm_03` (20.10)  \n",
    "* Outputs:\n",
    "  * (none)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a002c61d-99e2-4e20-a1fd-8d739a3afd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46b8acef-ef12-40d0-9d27-fde1bd8b7f00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from hashlib import sha256\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "import numpy as np\n",
    "from itertools import chain\n",
    "from transformers import BertTokenizerFast, BertForMaskedLM, BertModel\n",
    "from import_conart import conart\n",
    "from conart.mlm_masks import batched_text, batched_text_gan, get_equality_constraints\n",
    "from conart.sample import sample_site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b571992-7a21-4000-80e1-bab0f9d8babb",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") \\\n",
    "         if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9a62670-63f0-45f2-98b1-f8aa45b47866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11642"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = \"../data/raw_cx_data.json\"\n",
    "with open(data_path, \"r\", encoding=\"UTF-8\") as fin:\n",
    "    data = json.load(fin)\n",
    "## Check data is the same\n",
    "h = sha256()\n",
    "h.update(pickle.dumps(data))\n",
    "data_hash = h.digest().hex()[:6]\n",
    "assert data_hash == \"4063b4\"\n",
    "len(data) # should be 11642"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7556dcc-1a31-40c8-b142-9a41f7e4ab47",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read cv splits\n",
    "with open(\"../data/cv_splits_10.json\", \"r\") as fin:\n",
    "    cv_splits = json.load(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46be44f6-5e00-4f5c-ac66-aec6f4441879",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-chinese')\n",
    "# model = BertForMaskedLM.from_pretrained('bert-base-chinese')\n",
    "# model = BertForMaskedLM.from_pretrained('ckiplab/bert-base-chinese')\n",
    "model = BertForMaskedLM.from_pretrained('../data/models/apricot_mlm_03')\n",
    "model = model.to(device)\n",
    "ckip_model = BertForMaskedLM.from_pretrained('ckiplab/bert-base-chinese')\n",
    "ckip_model = ckip_model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce38a19-96c3-44c8-9985-a513758804be",
   "metadata": {},
   "source": [
    "## Checking input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d978cb6d-17eb-45b4-95a9-ece138f1f9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idxs, test_idxs = cv_splits[0].values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab1179ed-8332-46d9-99af-e5ca98da2f6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'board': 'BabyMother',\n",
       " 'text': ['再', '擠', '也', '擠', '不', '出來', '了'],\n",
       " 'cnstr': ['O', 'BX', 'IX', 'IX', 'IX', 'IX', 'O'],\n",
       " 'slot': ['O', 'BV', 'BC', 'BV', 'BC', 'BV', 'O'],\n",
       " 'cnstr_form': ['v', '也', 'v', '不', 'X'],\n",
       " 'cnstr_example': ['擠', '也', '擠', '不', '出來']}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx = data[1211]\n",
    "xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6eae2503-404a-4c48-b5f1-432570bc35e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['masked', 'text', 'mindex', 'mindex_bool']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = batched_text(data, train_idxs[:5], \"vslot\")\n",
    "def get_cnstr_eqs(cxinst):\n",
    "    cnstr_eqs = {\n",
    "        \"text\": \"\".join(chain.from_iterable(cxinst[\"text\"])),\n",
    "        \"form\": cxinst[\"cnstr_form\"],\n",
    "        \"example\": cxinst[\"cnstr_example\"],\n",
    "        \"eqs\": get_equality_constraints(cxinst)\n",
    "    }\n",
    "    return cnstr_eqs\n",
    "list(batch.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34750e05-eab1-4d53-a1c4-0b3efdbdf44b",
   "metadata": {},
   "source": [
    "## Calculate Unigram baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "074d156f-9ef2-4692-8e13-0bec68a2911f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "v_instances = []\n",
    "for idx in train_idxs:\n",
    "    try:\n",
    "        eqs = get_cnstr_eqs(data[idx])    \n",
    "    except ValueError:\n",
    "        continue\n",
    "        \n",
    "    for v, inst in zip(eqs[\"form\"], eqs[\"example\"]):\n",
    "        if re.match(\"[a-z0-9]+\", v):            \n",
    "            v_instances.append(inst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da918c22-0bb4-46e9-a008-e36ddc075d88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19778"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(v_instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "528bf19d-ecc1-499d-999f-24c0980244c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "uni_freq = Counter(chain.from_iterable(v_instances))\n",
    "def query_uni_freq(char):\n",
    "    return uni_freq.get(char, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a0b63b98-6f4e-4f81-94f9-c1738ac408f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3647, 2682, 4692, 1391, 5050, 5481, 5464, 6341, 3121, 3119]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uni_base_chars = [x[0] for x in uni_freq.most_common()]\n",
    "uni_top10_chars = [x[0] for x in uni_freq.most_common(10)]\n",
    "uni_base_ids = tokenizer.convert_tokens_to_ids(uni_base_chars)\n",
    "uni_top10_ids = tokenizer.convert_tokens_to_ids(uni_top10_chars)\n",
    "uni_top10_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f10f06d9-465d-461b-af2b-d4d577d8de3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "891"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(uni_base_chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e00ece2-ed07-488c-8337-fb2400f24b2e",
   "metadata": {},
   "source": [
    "## Compute Topk accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e5024cd7-5910-42f4-a405-152bfb39d762",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5a79017dc424cbc8877bbc99de1a447",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1165 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence too long, mindex exceeds max_len 7417\n"
     ]
    }
   ],
   "source": [
    "# acc_tables: models: conart, ckip, unigram, random (4) x (Top1, 5, 10)(3)\n",
    "acc_table = np.zeros((4, 3))\n",
    "N = 0\n",
    "\n",
    "for data_idx in tqdm(test_idxs):    \n",
    "    bb = batched_text(data, [data_idx], 'vslot')\n",
    "\n",
    "    text = bb[\"text\"][0]\n",
    "    mask_locs = bb[\"mindex\"][0]\n",
    "    mask_locs = mask_locs[mask_locs>0]  \n",
    "    try:\n",
    "        conart_samples = sample_site(bb, model, tokenizer, n_sample=10, max_len=500)[0]\n",
    "        ckip_samples = sample_site(bb, ckip_model, tokenizer, n_sample=10, max_len=500)[0]\n",
    "    except:\n",
    "        print(\"Sentence too long, mindex exceeds max_len\", data_idx)\n",
    "        continue\n",
    "    for i, mask_idx in enumerate(mask_locs):\n",
    "        tgt_char = text[mask_idx]\n",
    "        conart_preds = conart_samples[\"ids\"][i]    \n",
    "        ckip_preds = ckip_samples[\"ids\"][i]\n",
    "        tgt_idx = tokenizer.convert_tokens_to_ids(tgt_char)\n",
    "        # print(\"mask_idx, char, idx: \", mask_idx, tgt_char, tgt_idx)\n",
    "        random_choices = np.random.choice(uni_base_ids, 10)\n",
    "        acc_table[0] += np.array([\n",
    "              tgt_idx in conart_preds[:1],\n",
    "              tgt_idx in conart_preds[:5],\n",
    "              tgt_idx in conart_preds[:10]])\n",
    "        acc_table[1] += np.array([\n",
    "              tgt_idx in ckip_preds[:1],\n",
    "              tgt_idx in ckip_preds[:5],\n",
    "              tgt_idx in ckip_preds[:10]])\n",
    "        acc_table[2] += np.array([\n",
    "              tgt_idx in uni_top10_ids[:1],\n",
    "              tgt_idx in uni_top10_ids[:5],\n",
    "              tgt_idx in uni_top10_ids[:10],])\n",
    "        \n",
    "        acc_table[3] += np.array([\n",
    "              tgt_idx in random_choices[:1],\n",
    "              tgt_idx in random_choices[:5],\n",
    "              tgt_idx in random_choices[:10],])\n",
    "        N += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3d2dfe3a-fe89-4f0a-b50b-90b12544943f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Top1</th>\n",
       "      <th>Top5</th>\n",
       "      <th>Top10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CxLM</th>\n",
       "      <td>0.300522</td>\n",
       "      <td>0.507031</td>\n",
       "      <td>0.599839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bert-Base</th>\n",
       "      <td>0.061069</td>\n",
       "      <td>0.132583</td>\n",
       "      <td>0.182804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unigram</th>\n",
       "      <td>0.047409</td>\n",
       "      <td>0.156689</td>\n",
       "      <td>0.216553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random</th>\n",
       "      <td>0.000402</td>\n",
       "      <td>0.004821</td>\n",
       "      <td>0.011249</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Top1      Top5     Top10\n",
       "CxLM       0.300522  0.507031  0.599839\n",
       "Bert-Base  0.061069  0.132583  0.182804\n",
       "Unigram    0.047409  0.156689  0.216553\n",
       "Random     0.000402  0.004821  0.011249"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "acc_dfr = pd.DataFrame(acc_table/N, columns=[\"Top1\", \"Top5\", \"Top10\"], index=[\"CxLM\", \"Bert-Base\", \"Unigram\", \"Random\"])\n",
    "acc_dfr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d32003f-cb27-4dd7-9436-db7a64cd0647",
   "metadata": {},
   "source": [
    "## Output Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fba799d8-1901-4b97-82bd-036d09e10c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrr}\n",
      "\\toprule\n",
      "{} &      Top1 &      Top5 &     Top10 \\\\\n",
      "\\midrule\n",
      "CxLM      &  0.300522 &  0.507031 &  0.599839 \\\\\n",
      "Bert-Base &  0.061069 &  0.132583 &  0.182804 \\\\\n",
      "Unigram   &  0.047409 &  0.156689 &  0.216553 \\\\\n",
      "Random    &  0.000402 &  0.004821 &  0.011249 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(acc_dfr.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a7c7e7-bdc4-4afa-b537-1ab8c3b80019",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "947f7331-799e-457e-9b05-f707abd298e9",
   "metadata": {},
   "source": [
    "## MLM slots evals\n",
    "* Inputs:\n",
    "  * raw data: `../data/raw_cx_data.json` (10.01)\n",
    "  * CV splits: `../data/cv_splits_10.json` (10.01)\n",
    "* Outputs:\n",
    "  * losses data (with CV): `../data/ckip_bert_cnstr_losses.pkl`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a002c61d-99e2-4e20-a1fd-8d739a3afd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46b8acef-ef12-40d0-9d27-fde1bd8b7f00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from hashlib import sha256\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from transformers import BertTokenizerFast, BertForMaskedLM, BertModel\n",
    "from import_conart import conart\n",
    "from conart.mlm_masks import batched_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b571992-7a21-4000-80e1-bab0f9d8babb",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") \\\n",
    "         if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9a62670-63f0-45f2-98b1-f8aa45b47866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11642"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = \"../data/raw_cx_data.json\"\n",
    "with open(data_path, \"r\", encoding=\"UTF-8\") as fin:\n",
    "    data = json.load(fin)\n",
    "## Check data is the same\n",
    "h = sha256()\n",
    "h.update(pickle.dumps(data))\n",
    "data_hash = h.digest().hex()[:6]\n",
    "assert data_hash == \"4063b4\"\n",
    "len(data) # should be 11642"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7556dcc-1a31-40c8-b142-9a41f7e4ab47",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read cv splits\n",
    "with open(\"../data/cv_splits_10.json\", \"r\") as fin:\n",
    "    cv_splits = json.load(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46be44f6-5e00-4f5c-ac66-aec6f4441879",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-chinese')\n",
    "# model = BertForMaskedLM.from_pretrained('bert-base-chinese')\n",
    "model = BertForMaskedLM.from_pretrained('ckiplab/bert-base-chinese')\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce38a19-96c3-44c8-9985-a513758804be",
   "metadata": {},
   "source": [
    "## Checking input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d978cb6d-17eb-45b4-95a9-ece138f1f9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idxs, test_idxs = cv_splits[0].values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab1179ed-8332-46d9-99af-e5ca98da2f6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'board': 'BabyMother',\n",
       " 'text': ['再', '擠', '也', '擠', '不', '出來', '了'],\n",
       " 'cnstr': ['O', 'BX', 'IX', 'IX', 'IX', 'IX', 'O'],\n",
       " 'slot': ['O', 'BV', 'BC', 'BV', 'BC', 'BV', 'O'],\n",
       " 'cnstr_form': ['v', '也', 'v', '不', 'X'],\n",
       " 'cnstr_example': ['擠', '也', '擠', '不', '出來']}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx = data[1211]\n",
    "xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6eae2503-404a-4c48-b5f1-432570bc35e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['masked', 'text', 'mindex', 'mindex_bool']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = batched_text(data, train_idxs[:5], \"vslot\")\n",
    "list(batch.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "074d156f-9ef2-4692-8e13-0bec68a2911f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[135, 137,  -1,  -1,  -1,  -1],\n",
       "       [ 13,  15,  -1,  -1,  -1,  -1],\n",
       "       [  3,   5,  -1,  -1,  -1,  -1],\n",
       "       [  0,   1,   2,   4,   5,   6],\n",
       "       [  0,   2,  -1,  -1,  -1,  -1]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"mindex\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a826fa-19ed-488b-b4dd-bae771ec8094",
   "metadata": {},
   "source": [
    "## Function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "914cb830-5686-46a6-8abc-b4d4f75e400a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fct = CrossEntropyLoss(reduction=\"none\")\n",
    "def make_masked_ylabels(mindex: np.ndarray, ori_ids: torch.Tensor):            \n",
    "    ylabels = torch.zeros_like(ori_ids)-100\n",
    "    for i in range(mindex.shape[0]):\n",
    "        # add 1 for the extra [CLS] token added after tokenizer\n",
    "        j = mindex[i]+1        \n",
    "        j = j[(j>=0) & (j<512-2)]        \n",
    "        ylabels[i, j] = ori_ids[i, j]\n",
    "    return ylabels\n",
    "\n",
    "def compute_loss(logits, ylabels):\n",
    "    return loss_fct(logits, ylabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ee23edca-115d-479a-826b-7ec5d268e64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mlm_loss(model, train_idxs, use_mask, debug=False):\n",
    "    batch_size = 16\n",
    "    loss_vec = []    \n",
    "    \n",
    "    for i in range(0, len(train_idxs), batch_size):\n",
    "        data_idxs = train_idxs[i:i+batch_size]\n",
    "        batch = batched_text(data, data_idxs, use_mask)\n",
    "\n",
    "        # compute perplexity    \n",
    "        X = tokenizer(batch[\"masked\"], return_tensors=\"pt\", is_split_into_words=True, padding=True, truncation=True)\n",
    "        X = X.to(device)\n",
    "        Xori = tokenizer(batch[\"text\"], return_tensors=\"pt\", is_split_into_words=True, padding=True, truncation=True)\n",
    "        ylabels = make_masked_ylabels(batch[\"mindex\"], Xori[\"input_ids\"])\n",
    "        ylabels = ylabels.to(device)        \n",
    "        with torch.no_grad():\n",
    "            out = model(**X)\n",
    "            batch_loss = compute_loss(out.logits.swapdims(2, 1), ylabels)\n",
    "            # average over non-zero token losses\n",
    "            batch_loss = batch_loss.sum(1) / (batch_loss>0).sum(1)\n",
    "            loss_vec.extend(batch_loss.cpu().tolist())\n",
    "        if debug: break\n",
    "        \n",
    "    if debug:        \n",
    "        return {\"loss_vec\": np.array(loss_vec), \n",
    "                \"batch\": batch, \"ylabels\": ylabels, \"out\": out}\n",
    "    else:\n",
    "        return np.array(loss_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eca001cb-01b2-47c0-a301-6b761919bbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "Mtest = len(test_idxs)\n",
    "n_split = len(cv_splits)\n",
    "def make_design_iter():\n",
    "    return product([\"cnstr\", \"cslot\", \"vslot\"], # cnstr elements \n",
    "                   [\"raw\", \"shifted\", \"random\"]) # masked type\n",
    "\n",
    "def get_mask_condition(cx_elem, mask_type):\n",
    "    cx_code = \"cx\" if cx_elem == \"cnstr\" else cx_elem\n",
    "    mask_code = \"\" if mask_type == \"raw\" else mask_type+\"-\"\n",
    "    return mask_code+cx_code\n",
    "\n",
    "def print_stat(x):\n",
    "    print(\"M={:.4f}, SD={:.4f} ({} NaNs)\"\n",
    "          .format(np.nanmean(x), np.nanstd(x), np.sum(np.isnan(x))))\n",
    "\n",
    "def make_buffer():\n",
    "    ret = {}\n",
    "    for cx_elem, mtype in make_design_iter():\n",
    "        ret[f\"{cx_elem}_{mtype}\"] = \\\n",
    "            np.zeros((Mtest, n_split))\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470c31f5-1db7-4bf1-975c-9d27b6c65f7c",
   "metadata": {},
   "source": [
    "## Computing MLM Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bad2bf4a-6757-4dea-88b4-72dec101bfe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d1bf8f332f4433ba1e39f272391d17c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2647a9fed5d84c21a5bc0b54e7c46315",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb909028313f46bfaca09e7d79ebbc64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d3d00919ec749b5935929f24508a7af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2c2e13a004045d7b9e191595c8902d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "493eaddde0a44eb6bc6b0e50dbb59c13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dfdb54ace2c47389831fa5409947ba9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67bc9b4d90c641fb8752ee6113de92cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a8db3f753764b048e554fddf91d8573",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6626b1ae81814819887c45f0fc1ed63d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## masked\n",
    "losses = make_buffer()\n",
    "n_condition = len(list(make_design_iter()))\n",
    "for split_idx in range(n_split):\n",
    "    train_idxs, test_idxs = cv_splits[split_idx].values()\n",
    "    pbar = tqdm(total=n_condition)\n",
    "    for cx_elem, mtype in make_design_iter():        \n",
    "        cond_text = f\"{cx_elem}_{mtype}\"\n",
    "        pbar.set_description(f\"{split_idx+1: 2d}. {cond_text}\")\n",
    "        m_cond = get_mask_condition(cx_elem, mtype)        \n",
    "        loss_x = compute_mlm_loss(model, test_idxs, m_cond)        \n",
    "        losses[cond_text][:, split_idx] = loss_x            \n",
    "        pbar.update(1)\n",
    "    pbar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d32003f-cb27-4dd7-9436-db7a64cd0647",
   "metadata": {},
   "source": [
    "## Output pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "686a3d9e-671e-494e-be30-2f735bb6ae60",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/ckip_bert_cnstr_losses.pkl\", \"wb\") as fout:\n",
    "    pickle.dump(losses, fout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f014d676-dec6-42b0-9120-2112862c407d",
   "metadata": {},
   "source": [
    "## Losses with bert-base-chinese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "809a3136-64a4-4fbc-994a-847e614a120e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-chinese were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = BertForMaskedLM.from_pretrained('bert-base-chinese')\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0ba75b88-1a5c-4637-95c0-d1f20fd6e087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9006032ad07e4cb892f201d18d1461a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1689e7280a2d4f0ea0420733b4b4b7c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8653fa91d4274f299b2bca77b7d38777",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28f44c5e09b74aaf9064e9510e9593c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a59a1afa5b6e4c839de8fef6625629e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a824bfa57d34e05b39f7fc4ae17e830",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a54455e2bdac4fb5831d1d679786598d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cd306e72c134fdc9b44424fa838b31f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cf4b4fece8f4c7a80e9b57d099805e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acec0ee8ca124cd7af31a40cf0c06d21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## masked\n",
    "losses = make_buffer()\n",
    "n_condition = len(list(make_design_iter()))\n",
    "for split_idx in range(n_split):\n",
    "    train_idxs, test_idxs = cv_splits[split_idx].values()\n",
    "    pbar = tqdm(total=n_condition)\n",
    "    for cx_elem, mtype in make_design_iter():        \n",
    "        cond_text = f\"{cx_elem}_{mtype}\"\n",
    "        pbar.set_description(f\"{split_idx+1: 2d}. {cond_text}\")\n",
    "        m_cond = get_mask_condition(cx_elem, mtype)        \n",
    "        loss_x = compute_mlm_loss(model, test_idxs, m_cond)        \n",
    "        losses[cond_text][:, split_idx] = loss_x            \n",
    "        pbar.update(1)\n",
    "    pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "daf1dc8f-90e9-49cf-b339-6ed4c8241bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output pickle\n",
    "with open(\"../data/bert_base_cnstr_losses.pkl\", \"wb\") as fout:\n",
    "    pickle.dump(losses, fout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90414209-8f02-4e8f-82c2-1c76e11606af",
   "metadata": {},
   "source": [
    "## Workarea"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc7017c-6504-4274-8e80-45ba5df55e57",
   "metadata": {},
   "source": [
    "### the equality between the built-in loss and custom-made compute-loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e1a4f62-596a-467f-ad6e-2c0a90323360",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = {'masked': [['今', '[MASK]']],\n",
    " 'text': [['今', '天']],\n",
    " 'mindex': np.array([[1]]),\n",
    " 'mindex_bool': np.array([[ True]])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff99231c-7129-4007-8587-62393fba74ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.4197540283203125\n"
     ]
    }
   ],
   "source": [
    "X = tokenizer(batch[\"masked\"], return_tensors=\"pt\", is_split_into_words=True, padding=True, truncation=True)\n",
    "X = X.to(device)\n",
    "Xori = tokenizer(batch[\"text\"], return_tensors=\"pt\", is_split_into_words=True, padding=True, truncation=True)\n",
    "ylabels = make_masked_ylabels(batch[\"mindex\"], Xori[\"input_ids\"])\n",
    "ylabels = ylabels.to(device)\n",
    "with torch.no_grad():\n",
    "    out = model(**X, labels=ylabels)\n",
    "    loss_batch = out.loss.cpu().item()\n",
    "    print(loss_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c4b39709-59f1-4c79-a86c-ff14a9eca120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.4197540283203125"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = compute_loss(out.logits.swapdims(2, 1), ylabels)\n",
    "(loss.sum(1) / (loss>0).sum()).cpu().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ee91f937-6779-4ca4-ad39-0a713b0b3a6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-100, -100, 1921, -100]], device='cuda:0')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ylabels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded55c7f-78b1-4ebb-9805-b03492734aed",
   "metadata": {},
   "source": [
    "## For debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3a5ba708-274f-4c60-a6c1-2f96bb764237",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss_vec': array([3.59199357]),\n",
       " 'batch': {'masked': [['1',\n",
       "    '[MASK]',\n",
       "    'm',\n",
       "    '補',\n",
       "    '給',\n",
       "    '品',\n",
       "    '買',\n",
       "    '一',\n",
       "    '買',\n",
       "    '窩',\n",
       "    '著',\n",
       "    '先',\n",
       "    '看',\n",
       "    '這',\n",
       "    '幾',\n",
       "    '天',\n",
       "    '發',\n",
       "    '展',\n",
       "    '比',\n",
       "    '較',\n",
       "    '穩',\n",
       "    '第',\n",
       "    '一',\n",
       "    '次',\n",
       "    '過',\n",
       "    '年',\n",
       "    '留',\n",
       "    '在',\n",
       "    '高',\n",
       "    '[MASK]']],\n",
       "  'text': [['1',\n",
       "    'k',\n",
       "    'm',\n",
       "    '補',\n",
       "    '給',\n",
       "    '品',\n",
       "    '買',\n",
       "    '一',\n",
       "    '買',\n",
       "    '窩',\n",
       "    '著',\n",
       "    '先',\n",
       "    '看',\n",
       "    '這',\n",
       "    '幾',\n",
       "    '天',\n",
       "    '發',\n",
       "    '展',\n",
       "    '比',\n",
       "    '較',\n",
       "    '穩',\n",
       "    '第',\n",
       "    '一',\n",
       "    '次',\n",
       "    '過',\n",
       "    '年',\n",
       "    '留',\n",
       "    '在',\n",
       "    '高',\n",
       "    '雄']],\n",
       "  'mindex': array([[ 1, 29]]),\n",
       "  'mindex_bool': array([[ True,  True]])},\n",
       " 'ylabels': tensor([[-100, -100,  153, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "          -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "          -100, -100, -100, -100, -100, -100, 7413, -100]], device='cuda:0'),\n",
       " 'out': MaskedLMOutput(loss=None, logits=tensor([[[ -7.8451,  -7.3592,  -7.4479,  ...,  -4.9392,  -5.2561,  -6.0882],\n",
       "          [ -7.4459,  -6.5024,  -6.1484,  ...,  -2.9871,  -5.6584,  -4.3816],\n",
       "          [ -6.6090,  -5.0838,  -5.5333,  ...,  -3.6004,  -5.7260,  -2.7770],\n",
       "          ...,\n",
       "          [-10.1297,  -8.2715,  -8.4002,  ...,  -6.6741,  -8.2256,  -7.8910],\n",
       "          [-10.7031,  -7.9854,  -9.0852,  ...,  -6.6788,  -9.6741,  -8.8004],\n",
       "          [ -7.8438,  -7.3581,  -7.4467,  ...,  -4.9381,  -5.2545,  -6.0875]]],\n",
       "        device='cuda:0'), hidden_states=None, attentions=None)}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa = compute_mlm_loss(test_idxs[1:2], \"shifted-vslot\", debug=True)\n",
    "aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4a1b1ee4-501c-46e9-8e1d-7194c170b9cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b575d6277492445fa365671a4228c9f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'loss_vec': array([5.19510221]),\n",
       " 'batch': {'masked': [['我',\n",
       "    '覺',\n",
       "    '得',\n",
       "    '這',\n",
       "    '位',\n",
       "    '護',\n",
       "    '理',\n",
       "    '師',\n",
       "    '錯',\n",
       "    '就',\n",
       "    '錯',\n",
       "    '[MASK]',\n",
       "    '抽',\n",
       "    '了',\n",
       "    '一',\n",
       "    '[MASK]',\n",
       "    '不',\n",
       "    '理',\n",
       "    '性',\n",
       "    '孕',\n",
       "    '婦',\n",
       "    '的',\n",
       "    '血',\n",
       "    '吧',\n",
       "    '你',\n",
       "    '當',\n",
       "    '下',\n",
       "    '可',\n",
       "    '以',\n",
       "    '不',\n",
       "    '要',\n",
       "    '哭',\n",
       "    '好',\n",
       "    '好',\n",
       "    '跟',\n",
       "    '她',\n",
       "    '溝',\n",
       "    '通',\n",
       "    '請',\n",
       "    '她',\n",
       "    '換',\n",
       "    '人',\n",
       "    '抽',\n",
       "    '吧',\n",
       "    '樓',\n",
       "    '上',\n",
       "    '你',\n",
       "    '好']],\n",
       "  'text': [['我',\n",
       "    '覺',\n",
       "    '得',\n",
       "    '這',\n",
       "    '位',\n",
       "    '護',\n",
       "    '理',\n",
       "    '師',\n",
       "    '錯',\n",
       "    '就',\n",
       "    '錯',\n",
       "    '在',\n",
       "    '抽',\n",
       "    '了',\n",
       "    '一',\n",
       "    '位',\n",
       "    '不',\n",
       "    '理',\n",
       "    '性',\n",
       "    '孕',\n",
       "    '婦',\n",
       "    '的',\n",
       "    '血',\n",
       "    '吧',\n",
       "    '你',\n",
       "    '當',\n",
       "    '下',\n",
       "    '可',\n",
       "    '以',\n",
       "    '不',\n",
       "    '要',\n",
       "    '哭',\n",
       "    '好',\n",
       "    '好',\n",
       "    '跟',\n",
       "    '她',\n",
       "    '溝',\n",
       "    '通',\n",
       "    '請',\n",
       "    '她',\n",
       "    '換',\n",
       "    '人',\n",
       "    '抽',\n",
       "    '吧',\n",
       "    '樓',\n",
       "    '上',\n",
       "    '你',\n",
       "    '好']],\n",
       "  'mindex': array([[11, 15]]),\n",
       "  'mindex_bool': array([[ True,  True]])},\n",
       " 'ylabels': tensor([[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "          1762, -100, -100, -100,  855, -100, -100, -100, -100, -100, -100, -100,\n",
       "          -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "          -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "          -100, -100]], device='cuda:0'),\n",
       " 'out': MaskedLMOutput(loss=None, logits=tensor([[[ -7.4832,  -7.0938,  -7.0394,  ...,  -4.7316,  -4.2512,  -6.1847],\n",
       "          [-12.7166, -10.6621, -10.4491,  ...,  -5.6181,  -8.1767,  -9.5996],\n",
       "          [-15.0834, -12.1213, -13.1338,  ...,  -8.9814,  -9.1971, -13.5536],\n",
       "          ...,\n",
       "          [-10.6557, -10.0230,  -7.9081,  ...,  -3.3471,  -4.7994,  -6.6893],\n",
       "          [ -8.6336,  -6.7682,  -6.6582,  ...,  -3.6058,  -4.7936,  -5.3883],\n",
       "          [ -7.4842,  -7.0937,  -7.0400,  ...,  -4.7287,  -4.2499,  -6.1847]]],\n",
       "        device='cuda:0'), hidden_states=None, attentions=None)}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa = compute_mlm_loss([test_idxs[0]], \"random-cslot\", debug=True)\n",
    "aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba799d8-1901-4b97-82bd-036d09e10c78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
